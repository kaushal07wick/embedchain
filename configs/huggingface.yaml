llm:
  provider: huggingface
  model: 'google/flan-t5-xxl'
  config:
    temperature: 0.5
    max_tokens: 1000
    top_p: 0.5
    stream: false
